# LII: Linguistic Incendiary Index

> Measures how likely a piece of language (spoken, written, AI-generated) may trigger emotional conflict, imitation, or social unrest.

---

## Core Concepts

- **Incendiary Term Detection**
Identifies emotionally provocative words or frames.

- **Cultural Sensitivity Context**
Analyzes if the phrase triggers different meanings across groups.

- **Amplification Risk Score**
Predicts if the language is likely to go viral, mislead, or incite actions.

---

## Use Cases

- Detecting hate speech veiled in abstract language
- Evaluating AI-generated content risks
- Platform moderation and narrative conflict forecasting

---

## Linked Modules

- [EDRI-H](EDRI-H.md)
- [Trust Drift Map](TrustDrift.md)
