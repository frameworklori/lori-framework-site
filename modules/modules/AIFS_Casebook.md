modules/AIFS_Casebook.md

# AIFS Casebook: Realistic AI Fraud Scenarios

*Part of the AIFS Module (AI Fraud Spectrum) – Lori Framework*

This casebook includes simulated, realistic scenarios corresponding to the 8 fraud types defined in the AIFS module. These are designed to help stakeholders, educators, and public safety professionals understand the emotional, technical, and behavioral triggers involved in AI-driven scams.

---

## A1 – Voice Cloning Fraud

**Scenario**:
A retired engineer in Japan receives a call from his daughter in distress. “Dad, I’m stuck in Hong Kong jail. I need $5,000 bail. Please don’t hang up.” The voice matches perfectly. He wires the money within 10 minutes—only to receive a cheerful dinner message from the real daughter later.

---

## A2 – Deepfake Video Fraud

**Scenario**:
A viral TED Talk video shows Elon Musk announcing a new cryptocurrency initiative. The video appears flawless—eye contact, speech cadence, background. Hundreds invest within minutes. But the event never happened, and the website was a coordinated deepfake deployment.

---

## A3 – Romance Manipulation

**Scenario**:
A 58-year-old divorcee chats daily with a "Taiwanese doctor stationed abroad" via LINE. Poetic exchanges, daily good mornings, and photo sharing go on for 2 months. He suddenly requests emergency funds. She wires $6,000—then he vanishes. The "man" was a GPT chatbot using a stolen identity.

---

## A4 – Marriage Scam

**Scenario**:
A Southeast Asian woman quickly bonds with a lonely Japanese man through a dating platform. Within three months they marry. Weeks later, she says her father is dying and she needs to fly home, asking him to cover the ticket. She vanishes. The marriage was orchestrated by a scam ring using AI-crafted scripts.

---

## A5 – Immigration Investment Scam

**Scenario**:
A Chinese businessman is shown a professional-looking site advertising “Green Card via California Investment.” Lawyers appear on video calls, fluent in legalese. In truth, the site, faces, and voices are AI-generated. The legal team never existed.

---

## A6 – High Salary Job Scam

**Scenario**:
A college student receives a LinkedIn message offering a remote assistant role for $40/hour. He’s interviewed via voice chat by an AI-simulated CEO, who requests a security deposit before onboarding. The site, company, and people were all fake. He never sees the money again.

---

## A7 – Sextortion via Chat

**Scenario**:
A teenage boy connects with a "girl" on Instagram. Flirty messages escalate to a private video session. Later, he receives a screenshot of himself with threats: "Pay $800 or we’ll send this to your parents." The footage is actually a deepfake made using public images and synthetic voice input.

---

## A8 – Synthetic Identity Scam

**Scenario**:
A U.S. university receives 40 outstanding international student applications. Resumes, social profiles, transcripts look flawless. A reviewer notes identical phrasing patterns. On deeper analysis, 4 of the identities are AI-generated using fake recommendation letters, synthetic profile photos, and false IP trails.

---

## Attribution & Usage

These scenarios are fictional but constructed from real global fraud patterns.
If citing this document, please link to:
[→ AIFS Module](./AIFS.md)
[→ Lori Framework GitHub](https://github.com/frameworklori/lori-framework-site)

Contact: **frameworklori@gmail.com**
