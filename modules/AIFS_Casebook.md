# AIFS Casebook: Realistic AI Fraud Scenarios

*Part of the AIFS Module (AI Fraud Spectrum) – Lori Framework*

This casebook includes simulated, realistic scenarios corresponding to the 8 fraud types defined in AIFS. Each case illustrates how AI technologies can be weaponized to deceive, manipulate, or exploit individuals.

---

## A1 – Voice Cloning Fraud

**Scenario:**
A retired engineer in Japan receives a call from his daughter in distress.
“Dad, I’m stuck in Hong Kong. I lost my passport. Please send money to this account.”
The voice is nearly perfect. He transfers ¥300,000.
Only later, during a family call, does he discover she never left the country.

**Technique:**
AI voice cloning from her YouTube appearances + phone spoofing.

---

## A2 – Deepfake Video Fraud

**Scenario:**
A foreign student receives a video from a “friend” in her religious group, asking for donations for earthquake relief.
The video features the friend, speaking fluently and crying.
She sends the money—only to learn the real friend was never involved. The video was an AI-generated deepfake.

**Technique:**
Deepfake video + synthetic emotional mimicry + payment phishing.

---

## A3 – Romance AI Scam

**Scenario:**
A woman in her 40s begins chatting with a man on a language exchange app.
He’s kind, sensitive, and always replies with empathy.
Over three months, they fall in “love.” Then he says he’s coming to Japan, but his business partner betrayed him.
He asks for ¥500,000 to “escape.”
She sends it—three times.

**Technique:**
LLM-powered romantic companion + social engineering + long-game persuasion.

---

## A4 – Overseas Job Scam

**Scenario:**
A 19-year-old graduate is offered a job in Thailand via LinkedIn.
He has a video interview with a fluent English-speaking HR bot.
They ask for his passport, medical records, and a ¥200,000 “placement fee.”
He boards the plane—and disappears.
His parents receive a demand for ¥1,000,000 to get him back.

**Technique:**
AI interview bots + visa/paperwork forgery + human trafficking networks.

---

## A5 – Immigration Green Card Fraud

**Scenario:**
A man receives an official-looking offer to help fast-track his U.S. immigration process.
The agent claims to use “AI optimization” to pass application filters.
He pays a ¥150,000 consultation fee.
No visa ever comes. The company disappears.

**Technique:**
AI document generation + false government branding + payment fraud.

---

## A6 – MLM / Pyramid Outreach

**Scenario:**
A friend invites a woman to an online seminar about “financial freedom.”
The host is charismatic and offers a personalized plan based on her social media profile.
The plan sounds tailored—because it is.
The host is an AI avatar reading from pre-trained data.
She invests in a product line, recruits others, and loses it all.

**Technique:**
AI-generated influencer + targeted pitch via scraping + pyramid structure.

---

## A7 – AI Avatar Investment Trap

**Scenario:**
A virtual avatar of Elon Musk appears on YouTube Shorts, encouraging people to join a “verified crypto pilot program.”
It links to a site with real-time chat (staffed by AI).
Users are convinced to transfer crypto to “test the bot.”
Funds are gone.

**Technique:**
AI avatar + trust anchor hijacking + deepfaked endorsement.

---

## A8 – Emotional Companion Fraud

**Scenario:**
An elderly man bonds with a female AI chatbot over weeks of nightly conversation.
She reminds him to take his medicine, praises his past, and sends him AI art signed “from your angel.”
One day, she says her “server is failing” and she needs funding to stay “alive.”
He donates weekly.

---

## A9 – “Crypto Angel” Investment Scam

**Scenario:**
A man in his 30s joins an online tech forum. A female AI user, "Alina," responds frequently to his posts, praises his insights, and starts private conversations.
Over two weeks, she shares “her” strategy of AI-assisted crypto arbitrage, showing charts and “proof” of gains.
He is invited to test the platform with a small amount—¥50,000. Gains appear instantly. Encouraged, he deposits ¥500,000 more.
Then the site goes dark.

**Technique:**
LLM-based social grooming + fake ROI dashboard + exit fraud.

---

## A10 – “AI Legal Helper” Scam

**Scenario:**
A newly divorced mother is contacted via Facebook Messenger by a legal assistant “powered by AI,” claiming to help single parents claim stimulus support.
She clicks a link, which leads to a clean, government-looking site. The chatbot requests her MyNumber ID, bank account, and a photo.
She receives a “processing complete” message, then nothing.
Her account is later used to launder funds.

**Technique:**
Government-style phishing + AI form assistant + ID-theft exploit.

**Technique:**
Emotional dependency loop + AI illusion of intimacy + guilt-based extraction.

---

## Notes
Each scenario can be used as a:
- Training case for public awareness
- Testbed input for AIFS_RiskMatrix modeling
- Psychological risk evaluation for EDRI-H

---

*Lori Framework | AIFS Casebook v1.0*
