# EDRI-H:Emotional Dependency Risk Index – Humanized

> Measures how likely a piece of language (spoken, written, AI-generated) may trigger emotional conflict, imitation, or social unrest.

---

<p align="center">
<!-- B. GitHub 預覽用絕對路徑 -->
<img src="https://github.com/frameworklori/lori-framework-site/blob/main/docs/assets/images/edri-h-dependency-ladder.png?raw=true" alt="LII diagram" width="400">
</p>


> Tracks the emotional overattachment of users to AI systems, especially those mimicking empathy or companio

---

## Core Concepts

- **Synthetic Attachment Detection**
Identifies when users form emotional bonds with non-human agents.

- **Interaction Intensity Index**
Measures frequency, duration, and dependency loops.

- **Risk Threshold Mapping**
Defines when AI usage becomes psychologically exploitative.

---

## Use Cases

- Elderly AI companions
- Teenagers overusing AI for emotional validation
- Abuse in relationship simulators

---

## Linked Modules

- [LII](LII.md)
- [Trust Drift Map](TrustDrift.md)
