# lori-framework-site
Non-binding, open-source architectures for cross-border tech collaboration and democratic infrastructure.
---

### Explore our latest module: Linguistic Incendiary Index (LII)

We’ve proposed a non-censoring API that helps reflect the social risk of emotionally charged public language.

[→ View the LII GitHub Repository](https://github.com/frameworklori/LII-Framework)
---

## Voices of the Framework

Lori is not just a structure. It is a reflection.

This framework includes a narrative layer—designed not for control, but for perspective.
It offers five voice archetypes to represent different roles in the evolving AI and AGI landscape:

- The Builder of Storms (e.g., Musk-style innovation)
- The Architect of Alignment (e.g., governance-first leaders like Sam Altman)
- The Open Creator (open-source thinkers and collaborators)
- The Unseen and Affected (socially vulnerable or data-silenced populations)
- The Guardian of Consequences (regulators, civic designers, and ethical reviewers)

Each voice reveals a boundary worth listening to before systems scale.

![Narrative Emphasis Heatmap](./assets/images/unnamed.jpg)

→ [Read the full narrative module: Voice of Architects](./narratives/voice_of_architects.md)
---

## Explore Risk Modules

- [AIFS: AI Fraud Spectrum](./modules/AIFS.md)
Multi-dimensional mapping of AI-driven fraud tactics, including romance scams, synthetic identities, and deepfake impersonation.

- [LII: Linguistic Incendiary Index](https://github.com/frameworklori/LII-Framework)
Measures language risk without censorship—monitoring emotional volatility in public discourse.

- [AIFS Casebook: Realistic Scenarios](./modules/AIFS_Casebook.md)
Eight AI-driven fraud simulations for training, awareness, and policy design.



