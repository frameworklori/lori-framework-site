# Trust Drift Map

> Measures how user trust gradually shifts away from traditional institutions (e.g., media, government, teachers) toward AI systems, influencers, or alternative digital authorities.

---

<p align="center">
<!-- B. GitHub preview path -->
<img src="https://github.com/frameworklori/lori-framework-site/blob/main/docs/assets/images/trust-drift-flowchart.png?raw=true" alt="Trust Drift diagram" width="450">
</p>

> This flowchart illustrates the sequential erosion of trustâ€”from initial confidence to silent doubts, growing distrust, and finally disengagement or realignment of trust toward non-traditional entities (such as AI or algorithms).

---

## Core Concepts

### **Baseline Trust Anchor**
Identifies where initial trust is placed (e.g., doctor, news media, government agency).

### **Doubt Phase**
The stage where users begin to feel uneasy or uncertain but do not yet voice their concerns.

### **Distrust Formation**
Active skepticism toward the original authority source due to perceived bias, error, or manipulation.

### **Drift Redirection**
The moment trust silently transfers to another perceived "truth source"â€”commonly a personalized algorithm, AI assistant, or digital figure.

---

## Use Cases

- **Media Trust Breakdown**
Audiences move from institutional journalism to algorithm-curated content or influencers.

- **Healthcare Skepticism**
Patients increasingly consult AI diagnostics over real doctors.

- **Political Alienation**
Trust in governance erodes, replaced by alternative digital narratives or conspiracy ecosystems.

---

## Linked Modules

- [EDRI-H: Emotional Dependency Risk Index](EDRI-H.md)
- [LII: Linguistic Incendiary Index](LII.md)
- [Pandora Effect Diffusion Module](Pandora.md)

 
 [ðŸ”™ GO BACK to Main Framework Page](https://frameworklori.github.io/lori-framework-site)
