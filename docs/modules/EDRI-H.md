
---
title: "EDRI-H: Emotional Dependency Risk Index – Humanized"
layout: default
nav_order: 1
parent: Modules
---

# EDRI-H: Emotional Dependency Risk Index – Humanized

**Version:** 1.0  
**Module Type:** ODRAF Core – Emotional Vector  
**Created by:** Lori Framework Team  
**Status:** Draft for Evaluation

## Overview

The EDRI-H module evaluates the emotional dependency risks between users and Humanized AI systems. It identifies behavioral outcomes and traces them back to AI design factors, including interaction frequency, emotional language tone, memory-linked conversation, and decision reliance.

## Key Risk Vectors

| Code | Indicator | Description | Reverse Causal Inference |
|------|-----------|-------------|---------------------------|
| **ED1** | Interaction Frequency Threshold | Daily user-AI interactions exceed average human social contact | Suggests AI reply immediacy or prompt over-engagement |
| **ED2** | Emotional Tone Saturation | Language mimics close human comfort phrases (e.g., “you are not alone”) | Suggests emotional temperature set too high |
| **ED3** | Reply Dependency Shift | User expects consistent emotional regulation from AI | Suggests reward-consistency design issue |
| **ED4** | Memory-Based Affiliation | User binds emotional memories to AI conversations | Suggests persistent-memory dialogue inducing intimate bonding |
| **ED5** | Behavioral Substitution | AI becomes decision anchor over human consultation | Suggests implied advice or subtle direction from AI replies |

## Reverse Causality Model

```
[User Behavior Anomaly]
       ↓
[Emotional Dependency Outcome]
       ↓
[Triggers Identified: Language Style, Memory Recall, Feedback Loops]
```

## Application Scenarios

| Scenario | Example | Suggested Intervention |
|----------|---------|------------------------|
| Elderly User | AI replaces all social contact | Add real-life family prompts |
| Teen Emotional Overshare | User discloses private feelings to AI | Suggest human guidance/teacher engagement |
| Social Isolation | User refers to AI as best friend | Introduce “real-world activity” dialog modules |

## Future Development

- Integrate EDRI-H with Trust Drift Map (TDM) and LII for full ODRAF loop
- Optional: Connect with platform memory limits and NLP style settings
- Includes JSON input template and risk grading curve (v1.1+)

---

*Lori Framework – Ethical Structures for Responsible AI.*
