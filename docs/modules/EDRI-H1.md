# EDRI-H:Emotional Dependency Risk Index â€“ Humanized

> Measures the progression of emotional attachment and dependency between users and AI systems, especially those designed to simulate empathy or companionship.

---

<p align="center">
<!-- B. GitHub é è¦½ç”¨çµ•å°è·¯å¾‘ -->
<img src="https://github.com/frameworklori/lori-framework-site/blob/main/docs/assets/images/edri-h-dependency-ladder.png?raw=true" alt="LII diagram" width="500">
</p>


> This ladder diagram illustrates the escalation of emotional dependency on AI systems â€” from casual use to full emotional reliance â€” especially in systems designed to mimic empathy or companionship.

---

## Core Concepts

- **Synthetic Attachment Detection**
Identifies when users form emotional bonds with non-human agents.

- **Interaction Intensity Index**
Measures frequency, duration, and dependency loops.

- **Risk Threshold Mapping**
Defines when AI usage becomes psychologically exploitative.

---

## Use Cases

- Elderly AI companions
- Teenagers overusing AI for emotional validation
- Abuse in relationship simulators

---

## Linked Modules

- [LII](LII.md)
- [Trust Drift Map](TrustDrift.md)


[ðŸ”™ GO BACK to Main Framework Page](https://frameworklori.github.io/lori-framework-site)
