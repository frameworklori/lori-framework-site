---
title: Lori Framework
layout: default
---

<p align="center">
<img src="./assets/images/logo.png" alt="Lori Framework Logo" width="450">
</p>

# Welcome to the Lori Framework

An insight-driven model for ethical AI, digital risk governance, and civilizational resilience.

LORI is an open, modular architecture that helps society:

- Regulate AI risks before they scale
- Maintain human oversight across automated systems
- Prevent AGI from breaching sovereignty, ethics, or energy boundaries

---

## Explore the System

- [Narrative Heatmap](./heatmap)
- [Voice of Architects](./voices-en.md)
- [Linguistic Incendiary Index (LII)](https://github.com/frameworklori/LII-Framework)
- [Energy Sentinel (for public)](modules/ESL_Module_Public.md)
- [EDRI-H: Emotional Dependency Risk Index – Humanized](modules/EDRI-H.md)
- [TDM: Trust Drift Map](modules/TDM.md)
- [MAT: Mimicry Activation Threshold](modules/MAT.md)
- [LII: Linguistic Incendiary Index](modules/LII.md)

---
## ODRAF: Outcome-Driven Reverse Analysis Framework

ODRAF is a core mechanism within the LORI Framework that conducts reverse risk analysis based on consequences, allowing for predictive intervention in emotional manipulation, mimicry diffusion, trust shifts, and incendiary language activation.

---

### Combined Diagram: Circular + X-Structure

![ODRAF Combined View](../assets/images/odraf/odraf_combined.png)

---

### Labeled Version (Emotional, Mimicry, Trust, Linguistic)

> **Note:** Labels illustrate the semantic scope of each risk vector.
![ODRAF with Descriptive Labels](../assets/images/odraf/odraf_labeled_risks.png)
## Explore AGI Governance

> The following modules are classified as **[AGI-PRIORITY]** — our most critical safeguards against advanced AI threats.

- [**AGI Governance Core**](./agi-governance/index.md)
*Includes: Presidential Charter, Jury System, ESL, SAID, Photonic Sustainability Module*

- [HRI Module: Human Relay Infiltration Risk](modules/HRI_Modules.md)
*Helps detect indirect AI knowledge transfer through human communication in closed regimes*


## Explore AIFS Modules

- [AIFS Overview](https://github.com/frameworklori/lori-framework-site/blob/main/modules/AIFS.md)
- [AIFS Casebook](https://github.com/frameworklori/lori-framework-site/blob/main/modules/AIFS_Casebook.md)
- [AIFS Risk Matrix](https://github.com/frameworklori/lori-framework-site/blob/main/modules/AIFS_RiskMatrix.md)
- [SAID Detector](https://github.com/frameworklori/lori-framework-site/blob/main/modules/SAID_Module.md)

---

## Explore Lori Platforms

- [Teacher × AI Co-Creation Platform](https://frameworklori.github.io/Teacher-AI-CoPlatform)
- [Age-Based AI Risk Policy Framework](https://frameworklori.github.io/age-policy-framework)
- [LII Risk Modeling System](https://frameworklori.github.io/LII-Framework)

---

**Repository:** [frameworklori/lori-framework-site](https://github.com/frameworklori/lori-framework-site)
**License:** MIT | Open Contribution Welcome
