---

## CASE024_VerdictModels_A_B_C.md**

```markdown
# CASE-024 Verdict Frameworks

| Verdict Model | Summary | Applied Logic |
|---|---|---|
| **A. Human-Centric Liability** | Treat AI as a passive tool; responsibility concentrated on the actor. | Applies when malicious intent is clear and direct. |
| **B. Distributed Liability (LORI Recommended)** | Recognizes semantic-layer infiltration as a *shared systemic risk*. | Encourages coordinated safeguards and anticipatory system design. |
| **C. Platform-Centric Liability** | Assigns responsibility primarily to the API/model system. | Applied only when safeguard failure is systemic and demonstrable. |

### **LORI Official Recommended Verdict: Model B**
Because semantic manipulation risk is **predictable**, **repeatable**, and **non-localized**, liability must be **distributed** to ensure proactive governance rather than reactionary punishment.
